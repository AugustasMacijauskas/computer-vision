{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"id":"80esyABxMk8n"}},{"cell_type":"code","source":"from functools import partial\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict, Counter\nimport copy\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\n\n# Basic libraries for data manipulation\nimport torch\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix\nimport seaborn as sns\nimport pickle\n\n# PyTorch parts\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms, datasets","metadata":{"id":"R-aV595PMk8n","execution":{"iopub.status.busy":"2023-01-10T12:56:37.092966Z","iopub.execute_input":"2023-01-10T12:56:37.093563Z","iopub.status.idle":"2023-01-10T12:56:37.103451Z","shell.execute_reply.started":"2023-01-10T12:56:37.093513Z","shell.execute_reply":"2023-01-10T12:56:37.102339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=2022)","metadata":{"id":"6FPkmhP2Mk8n","execution":{"iopub.status.busy":"2023-01-10T12:56:37.105444Z","iopub.execute_input":"2023-01-10T12:56:37.106467Z","iopub.status.idle":"2023-01-10T12:56:37.116792Z","shell.execute_reply.started":"2023-01-10T12:56:37.106286Z","shell.execute_reply":"2023-01-10T12:56:37.115938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{"id":"SueiKdMNMk8o"}},{"cell_type":"code","source":"AUGMENTATIONS_ENGINE = \"torchvision\"\nOUTPUT_SIZE = 1","metadata":{"id":"koPwlrHJMk8o","execution":{"iopub.status.busy":"2023-01-10T12:56:37.118337Z","iopub.execute_input":"2023-01-10T12:56:37.119033Z","iopub.status.idle":"2023-01-10T12:56:37.125413Z","shell.execute_reply.started":"2023-01-10T12:56:37.118998Z","shell.execute_reply":"2023-01-10T12:56:37.124510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\nif torch.cuda.device_count() == 1: device = \"cuda\"\nelif torch.cuda.device_count() == 2: device = \"cuda:0\"\ndevice = torch.device(device)\ndevice","metadata":{"id":"8T5rGiQcMk8o","outputId":"cf25e9a9-6284-4a98-dc22-0b3f48b34c74","execution":{"iopub.status.busy":"2023-01-10T12:56:37.128283Z","iopub.execute_input":"2023-01-10T12:56:37.128695Z","iopub.status.idle":"2023-01-10T12:56:37.137954Z","shell.execute_reply.started":"2023-01-10T12:56:37.128652Z","shell.execute_reply":"2023-01-10T12:56:37.136957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training hyperparameters\nBATCH_SIZE = 128\nSHOW_PROGRESS = False","metadata":{"id":"xVC6cspPMk8o","execution":{"iopub.status.busy":"2023-01-10T12:56:37.139102Z","iopub.execute_input":"2023-01-10T12:56:37.140069Z","iopub.status.idle":"2023-01-10T12:56:37.146565Z","shell.execute_reply.started":"2023-01-10T12:56:37.140031Z","shell.execute_reply":"2023-01-10T12:56:37.145712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{"id":"A6hJpV32Mk8o"}},{"cell_type":"markdown","source":"**Download the data**","metadata":{"id":"agIEAloWMk8o"}},{"cell_type":"code","source":"# Switch this between CIFAR-10 and CIFAR-100 when needed\n\nN_LABELS = 10\ndataset = datasets.CIFAR10(root=\".\", train=False, download=True)\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:37.147995Z","iopub.execute_input":"2023-01-10T12:56:37.148627Z","iopub.status.idle":"2023-01-10T12:56:42.219282Z","shell.execute_reply.started":"2023-01-10T12:56:37.148592Z","shell.execute_reply":"2023-01-10T12:56:42.218156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = dataset[9]\nprint(y)\nplt.imshow(x)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:42.220657Z","iopub.execute_input":"2023-01-10T12:56:42.222443Z","iopub.status.idle":"2023-01-10T12:56:42.406036Z","shell.execute_reply.started":"2023-01-10T12:56:42.222387Z","shell.execute_reply":"2023-01-10T12:56:42.405136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nlabel_to_files = { label: [idx for idx in range(len(dataset)) if dataset[idx][1] == label] for label in tqdm(range(N_LABELS)) }\nlabel_to_files.keys()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:42.407287Z","iopub.execute_input":"2023-01-10T12:56:42.407722Z","iopub.status.idle":"2023-01-10T12:56:45.612112Z","shell.execute_reply.started":"2023-01-10T12:56:42.407686Z","shell.execute_reply":"2023-01-10T12:56:45.611064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set([len(value) for value in label_to_files.values()])","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:45.613464Z","iopub.execute_input":"2023-01-10T12:56:45.613836Z","iopub.status.idle":"2023-01-10T12:56:45.621274Z","shell.execute_reply.started":"2023-01-10T12:56:45.613798Z","shell.execute_reply":"2023-01-10T12:56:45.620348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_to_files[0][:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:45.625832Z","iopub.execute_input":"2023-01-10T12:56:45.626463Z","iopub.status.idle":"2023-01-10T12:56:45.638175Z","shell.execute_reply.started":"2023-01-10T12:56:45.626427Z","shell.execute_reply":"2023-01-10T12:56:45.637196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"3xNXw3aKMk8s"}},{"cell_type":"code","source":"%%time\n\ndef draw_image(label_to_files, label, probability_same=0.5):\n    are_same = random.random() < probability_same\n    \n    labels = list(label_to_files.keys())\n    if not are_same: label = random.choice([lbl for lbl in labels if lbl != label])\n    \n    return random.choice(label_to_files[label]), are_same\n\nout = draw_image(label_to_files=label_to_files, label=0, probability_same=0.5)\nout","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:45.639642Z","iopub.execute_input":"2023-01-10T12:56:45.640032Z","iopub.status.idle":"2023-01-10T12:56:45.765832Z","shell.execute_reply.started":"2023-01-10T12:56:45.639996Z","shell.execute_reply":"2023-01-10T12:56:45.764556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(2022)\n\nbalanced_pairs = [\n    draw_image(label_to_files=label_to_files, label=dataset[idx][1], probability_same=0.5)[0] for idx in range(len(dataset))\n]\nsparse_pairs = [\n    draw_image(label_to_files=label_to_files, label=dataset[idx][1], probability_same=1 / N_LABELS)[0] for idx in range(len(dataset))\n]\nlen(balanced_pairs), len(sparse_pairs)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:45.767424Z","iopub.execute_input":"2023-01-10T12:56:45.768488Z","iopub.status.idle":"2023-01-10T12:56:46.482687Z","shell.execute_reply.started":"2023-01-10T12:56:45.768427Z","shell.execute_reply":"2023-01-10T12:56:46.481783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean([dataset[i][1] == dataset[balanced_pairs[i]][1] for i in range(len(dataset))])","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:46.484123Z","iopub.execute_input":"2023-01-10T12:56:46.484498Z","iopub.status.idle":"2023-01-10T12:56:47.093099Z","shell.execute_reply.started":"2023-01-10T12:56:46.484454Z","shell.execute_reply":"2023-01-10T12:56:47.092108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean([dataset[i][1] == dataset[sparse_pairs[i]][1] for i in range(len(dataset))])","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:47.094341Z","iopub.execute_input":"2023-01-10T12:56:47.095179Z","iopub.status.idle":"2023-01-10T12:56:47.674487Z","shell.execute_reply.started":"2023-01-10T12:56:47.095127Z","shell.execute_reply":"2023-01-10T12:56:47.673395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(\n        self, dataset, label_to_files, paired_files,\n        augmentations:transforms.Compose=None, augmentations_engine:str=\"torchvision\"\n    ):        \n        assert augmentations_engine in [\"torchvision\", \"albumentations\"], \\\n            \"Variable augmentations_engine has to be one of torchvision, albumentations.\"\n        \n        self.dataset = dataset\n        self.label_to_files = label_to_files\n        self.paired_files = paired_files\n        self.augmentations = augmentations\n        self.augmentations_engine = augmentations_engine\n\n    def __len__(self):\n        return len(self.dataset)\n\n    \n    def _get_files_valid(self, idx):\n        x1, y1 = self.dataset[idx]\n        x2, y2 = self.dataset[self.paired_files[idx]]\n        same = y1 == y2\n            \n        return x1, x2, same\n    \n\n    def __getitem__(self, idx):\n        image1, image2, same = self._get_files_valid(idx)\n        \n        if self.augmentations is not None:\n            if self.augmentations_engine == \"albumentations\":\n                image1 = self.augmentations(image=image1)[\"image\"]\n                image2 = self.augmentations(image=image2)[\"image\"]\n            else:\n                image1 = self.augmentations(image1)\n                image2 = self.augmentations(image2)\n\n            \n        return { \"image1\": image1, \"image2\": image2, \"label\": torch.tensor(float(same)) }","metadata":{"id":"ud0UXwCYMk8s","execution":{"iopub.status.busy":"2023-01-10T12:56:47.675960Z","iopub.execute_input":"2023-01-10T12:56:47.676667Z","iopub.status.idle":"2023-01-10T12:56:47.687757Z","shell.execute_reply.started":"2023-01-10T12:56:47.676628Z","shell.execute_reply":"2023-01-10T12:56:47.686616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_augmentations = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), # Converting images to tensors\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:47.689418Z","iopub.execute_input":"2023-01-10T12:56:47.689819Z","iopub.status.idle":"2023-01-10T12:56:47.701511Z","shell.execute_reply.started":"2023-01-10T12:56:47.689784Z","shell.execute_reply":"2023-01-10T12:56:47.700647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_balanced_dataset = CustomDataset(\n    dataset=dataset,\n    label_to_files=label_to_files, paired_files=balanced_pairs,\n    augmentations=valid_augmentations, augmentations_engine=AUGMENTATIONS_ENGINE\n)\nvalid_sparse_dataset = CustomDataset(\n    dataset=dataset,\n    label_to_files=label_to_files, paired_files=sparse_pairs,\n    augmentations=valid_augmentations, augmentations_engine=AUGMENTATIONS_ENGINE\n)","metadata":{"id":"-H_sHnQ8Mk8s","execution":{"iopub.status.busy":"2023-01-10T12:56:47.702789Z","iopub.execute_input":"2023-01-10T12:56:47.703283Z","iopub.status.idle":"2023-01-10T12:56:47.711590Z","shell.execute_reply.started":"2023-01-10T12:56:47.703243Z","shell.execute_reply":"2023-01-10T12:56:47.710722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item = valid_balanced_dataset[0]\nprint(item[\"label\"])\nplt.imshow(item[\"image1\"].permute(1, 2, 0))\nplt.show()\nplt.imshow(item[\"image2\"].permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:47.713037Z","iopub.execute_input":"2023-01-10T12:56:47.713513Z","iopub.status.idle":"2023-01-10T12:56:48.398622Z","shell.execute_reply.started":"2023-01-10T12:56:47.713479Z","shell.execute_reply":"2023-01-10T12:56:48.396702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item = valid_sparse_dataset[0]\nprint(item[\"label\"])\nplt.imshow(item[\"image1\"].permute(1, 2, 0))\nplt.show()\nplt.imshow(item[\"image2\"].permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:48.400097Z","iopub.execute_input":"2023-01-10T12:56:48.400514Z","iopub.status.idle":"2023-01-10T12:56:48.936979Z","shell.execute_reply.started":"2023-01-10T12:56:48.400456Z","shell.execute_reply":"2023-01-10T12:56:48.936130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid_balanced_dataset), len(valid_sparse_dataset)","metadata":{"id":"3ASCP604Mk8t","outputId":"3d457cf9-ecd7-4042-ef3a-baad712ab397","execution":{"iopub.status.busy":"2023-01-10T12:56:48.941009Z","iopub.execute_input":"2023-01-10T12:56:48.943237Z","iopub.status.idle":"2023-01-10T12:56:48.952502Z","shell.execute_reply.started":"2023-01-10T12:56:48.943200Z","shell.execute_reply":"2023-01-10T12:56:48.951581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloaders","metadata":{"id":"EQydXNSFMk8t"}},{"cell_type":"code","source":"valid_kwargs = {\n    \"batch_size\": BATCH_SIZE,\n    \"shuffle\": False,\n    \"drop_last\": False,\n    \"num_workers\": 2,\n    \"pin_memory\": device.type == \"cuda\",\n}\n\nvalid_balanced_dataloader = DataLoader(valid_balanced_dataset, **valid_kwargs)\nvalid_sparse_dataloader = DataLoader(valid_sparse_dataset, **valid_kwargs)","metadata":{"id":"ZKoPhrVWMk8t","execution":{"iopub.status.busy":"2023-01-10T12:56:48.956373Z","iopub.execute_input":"2023-01-10T12:56:48.957796Z","iopub.status.idle":"2023-01-10T12:56:48.966661Z","shell.execute_reply.started":"2023-01-10T12:56:48.957760Z","shell.execute_reply":"2023-01-10T12:56:48.965627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {\n    \"valid_balanced_dataloader\": valid_balanced_dataloader,\n    \"valid_sparse_dataloader\": valid_sparse_dataloader,\n}","metadata":{"id":"w60NUnkmMk8t","execution":{"iopub.status.busy":"2023-01-10T12:56:48.969552Z","iopub.execute_input":"2023-01-10T12:56:48.971230Z","iopub.status.idle":"2023-01-10T12:56:48.978344Z","shell.execute_reply.started":"2023-01-10T12:56:48.970815Z","shell.execute_reply":"2023-01-10T12:56:48.977436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nbatch = next(iter(dataloaders[\"valid_balanced_dataloader\"]))\nbatch[\"image1\"].shape, batch[\"image2\"].shape, batch[\"label\"].shape","metadata":{"id":"m7bkVCdxMk8t","outputId":"b6e3c601-6366-48c8-fe5b-0e43e7d482f4","execution":{"iopub.status.busy":"2023-01-10T12:56:48.979846Z","iopub.execute_input":"2023-01-10T12:56:48.981623Z","iopub.status.idle":"2023-01-10T12:56:55.244426Z","shell.execute_reply.started":"2023-01-10T12:56:48.981588Z","shell.execute_reply":"2023-01-10T12:56:55.243236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch[\"label\"][:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:55.246778Z","iopub.execute_input":"2023-01-10T12:56:55.247241Z","iopub.status.idle":"2023-01-10T12:56:55.260205Z","shell.execute_reply.started":"2023-01-10T12:56:55.247195Z","shell.execute_reply":"2023-01-10T12:56:55.258731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"xb7fqoR-Mk8t"}},{"cell_type":"code","source":"class SimilarityModel(nn.Module):\n    def __init__(self, backbone_model, backbone_output_size, output_size=OUTPUT_SIZE):\n        super().__init__()\n        \n        self.backbone_model = backbone_model\n        \n        input_size = 3 * backbone_output_size + 2\n        self.classifier = nn.Sequential(\n            nn.BatchNorm1d(num_features=input_size),\n            nn.Dropout(p=0.25),\n            nn.Linear(in_features=input_size, out_features=512, bias=True),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(num_features=512),\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=512, out_features=output_size, bias=True),\n        )\n    \n    def forward(self, inputs):\n        image1, image2 = inputs\n        out1 = self.backbone_model(image1)\n        out2 = self.backbone_model(image2)\n        \n        # Use both vectors, their difference squared and the distance between them as input features\n        # to the classification head\n        diff_squared = (out1 - out2) ** 2\n        cosine_similarity = F.cosine_similarity(out1, out2, dim=-1).unsqueeze(1)\n        \n        concatenated_features = torch.hstack([\n            out1, out2,\n            diff_squared, cosine_similarity,\n            diff_squared.sum(dim=1, keepdim=True).sqrt()\n        ])\n        out = self.classifier(concatenated_features).squeeze()\n        \n        return out\n\n\ndef get_similarity_model(pretrained=True, output_size=OUTPUT_SIZE, device=device):\n    backbone_model = models.efficientnet_b0(pretrained=pretrained)\n    backbone_output_size = backbone_model.classifier[1].in_features\n    backbone_model.classifier = nn.Identity()\n    \n    model = SimilarityModel(\n        backbone_model=backbone_model, backbone_output_size=backbone_output_size, output_size=output_size\n    )\n    model.to(device)\n    \n    return model\n\nmodel = get_similarity_model(pretrained=False, output_size=OUTPUT_SIZE, device=device)\nsum([p.numel() for p in model.parameters()]) # number of parameters in the model","metadata":{"id":"slfT1PbdMk8t","outputId":"448e84b0-1dee-4398-b8ee-c4d88a9f5037","execution":{"iopub.status.busy":"2023-01-10T12:56:55.262057Z","iopub.execute_input":"2023-01-10T12:56:55.262421Z","iopub.status.idle":"2023-01-10T12:56:55.433479Z","shell.execute_reply.started":"2023-01-10T12:56:55.262390Z","shell.execute_reply":"2023-01-10T12:56:55.432405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nwith torch.no_grad():\n    out = model((batch[\"image1\"].to(device), batch[\"image2\"].to(device)))\nout.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:56:55.435198Z","iopub.execute_input":"2023-01-10T12:56:55.435551Z","iopub.status.idle":"2023-01-10T12:57:04.020940Z","shell.execute_reply.started":"2023-01-10T12:56:55.435517Z","shell.execute_reply":"2023-01-10T12:57:04.019974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass Metric:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n\n    name: str\n    total_value:int = 0\n    total_samples:int = 0\n    avg:int = 0\n\n    def reset(self):\n        self.total_value = 0\n        self.total_samples = 0\n        self.avg = 0\n\n    def update(self, loss, predictions, is_correct, new_count=1):\n        new_value = self._compute_value(loss, predictions, is_correct, new_count)\n        \n        self.total_value += new_value\n        self.total_samples += new_count\n        self.avg = self.total_value / self.total_samples\n    \n    # Metric specializes\n    def _compute_value(self, loss, predictions, is_correct, new_count):\n        if self.name == \"loss\": return loss.item() * new_count\n        else: return is_correct.sum().item()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:04.022502Z","iopub.execute_input":"2023-01-10T12:57:04.023120Z","iopub.status.idle":"2023-01-10T12:57:04.032285Z","shell.execute_reply.started":"2023-01-10T12:57:04.023082Z","shell.execute_reply":"2023-01-10T12:57:04.031274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass Learner:\n    \"\"\"\n    Container for various model/training variables\n    \"\"\"\n    \n    model:nn.Module\n    device:torch.device\n    dataloaders:dict\n    metric_values:dict\n    stage:str = \"train\"\n    optimizer:optim.Optimizer = None\n    lr_scheduler:optim.lr_scheduler._LRScheduler = None\n    lrs:list = field(default_factory=list)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:04.038083Z","iopub.execute_input":"2023-01-10T12:57:04.038398Z","iopub.status.idle":"2023-01-10T12:57:04.045322Z","shell.execute_reply.started":"2023-01-10T12:57:04.038373Z","shell.execute_reply":"2023-01-10T12:57:04.044215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iterate(learner, perform_backward_pass:bool=False, threshold:float=0.5, show_progress:bool=False):\n    all_labels = []\n    all_predictions = []\n    \n    metrics = [Metric(name=\"loss\"), Metric(name=\"acc\")]\n    \n    dl = learner.dataloaders[f\"{learner.stage}_dataloader\"]\n    loop = tqdm(dl, total=len(dl), leave=False) if show_progress else dl\n    for batch in loop:\n        inputs1 = batch[\"image1\"].to(learner.device)\n        inputs2 = batch[\"image2\"].to(learner.device)\n        labels = batch[\"label\"].to(learner.device)\n\n        outputs = learner.model((inputs1, inputs2))\n\n        # Calculate the loss\n        loss = F.binary_cross_entropy_with_logits(outputs, labels)\n    \n        if perform_backward_pass:\n            learner.optimizer.zero_grad()\n            loss.backward()\n\n            learner.optimizer.step()\n            \n            learner.lrs.append(learner.lr_scheduler.get_last_lr()[0])\n            learner.lr_scheduler.step()\n        \n        predictions = outputs.detach() >= torch.log(torch.tensor(threshold / (1 - threshold)))\n        is_correct = (predictions == labels).long()\n        for metric in metrics:\n            metric.update(loss=loss, predictions=predictions, is_correct=is_correct, new_count=batch[\"label\"].shape[0])\n        \n        all_labels.append(labels)\n        all_predictions.append(predictions)\n    \n    # Calculate loss and acc\n    for metric in metrics:\n        learner.metric_values[f\"{learner.stage}_{metric.name}\"].append(metric.avg)\n    \n    # Calculate the f1 metric\n    all_labels, all_predictions = torch.hstack(all_labels).cpu(), torch.hstack(all_predictions).cpu()\n    f1 = f1_score(all_labels, all_predictions)\n    learner.metric_values[f\"{learner.stage}_f1\"].append(f1)\n    \n    return all_labels, all_predictions","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:04.046761Z","iopub.execute_input":"2023-01-10T12:57:04.047443Z","iopub.status.idle":"2023-01-10T12:57:04.059393Z","shell.execute_reply.started":"2023-01-10T12:57:04.047407Z","shell.execute_reply":"2023-01-10T12:57:04.058402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"TRQ4huYsMk8u"}},{"cell_type":"code","source":"validation_stages = [\"valid_balanced\", \"valid_sparse\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:04.060640Z","iopub.execute_input":"2023-01-10T12:57:04.061531Z","iopub.status.idle":"2023-01-10T12:57:04.074072Z","shell.execute_reply.started":"2023-01-10T12:57:04.061486Z","shell.execute_reply":"2023-01-10T12:57:04.073047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_values = {\n    \"_\".join([split, metric]): [] for split in validation_stages for metric in [\"loss\", \"acc\", \"f1\"]\n}\nmetric_values","metadata":{"id":"x9kr3yCcMk8u","outputId":"2b82d7f1-a5b5-411e-e000-4487af3d4819","execution":{"iopub.status.busy":"2023-01-10T12:57:04.076791Z","iopub.execute_input":"2023-01-10T12:57:04.077437Z","iopub.status.idle":"2023-01-10T12:57:04.087629Z","shell.execute_reply.started":"2023-01-10T12:57:04.077410Z","shell.execute_reply":"2023-01-10T12:57:04.086522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner = Learner(\n    model=get_similarity_model(pretrained=False, output_size=OUTPUT_SIZE, device=device),\n    device=device,\n    dataloaders=dataloaders,\n    metric_values=metric_values,\n)","metadata":{"id":"-r7QeaNWMk8u","execution":{"iopub.status.busy":"2023-01-10T12:57:04.088889Z","iopub.execute_input":"2023-01-10T12:57:04.089410Z","iopub.status.idle":"2023-01-10T12:57:04.237736Z","shell.execute_reply.started":"2023-01-10T12:57:04.089377Z","shell.execute_reply":"2023-01-10T12:57:04.236679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"checkpoint = torch.load(\"path/to/model/weights\")\nlearner.model.load_state_dict(checkpoint)\nlearner.model.eval();","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:04.239212Z","iopub.execute_input":"2023-01-10T12:57:04.239563Z","iopub.status.idle":"2023-01-10T12:57:04.637647Z","shell.execute_reply.started":"2023-01-10T12:57:04.239530Z","shell.execute_reply":"2023-01-10T12:57:04.636618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nclasses = [\"dissimilar\", \"similar\"]\n\nfig, axes = plt.subplots(1, 1, figsize=(5, 5))\nfor stage, ax in zip([\"valid_balanced\"], [axes]):\n    print(stage)\n    learner.stage = stage\n    with torch.no_grad():\n        y_true, y_predicted = iterate(learner=learner, perform_backward_pass=False, threshold=0.5, show_progress=True)\n    conf_matrix = confusion_matrix(y_true, y_predicted, normalize='true')\n\n    sns.heatmap(\n        conf_matrix, ax=ax, xticklabels=classes, yticklabels=classes, annot=True, cbar=False, square=True)\n    ax.set_title(stage)\n    \nfig.tight_layout()\nplt.show()","metadata":{"id":"TtBfj9VYOtj7","outputId":"90b80a65-ba8a-43f5-8f40-beb6470eba47","execution":{"iopub.status.busy":"2023-01-09T17:27:46.285446Z","iopub.execute_input":"2023-01-09T17:27:46.286042Z","iopub.status.idle":"2023-01-09T17:28:36.495347Z","shell.execute_reply.started":"2023-01-09T17:27:46.286005Z","shell.execute_reply":"2023-01-09T17:28:36.493616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for metric_name in sorted(learner.metric_values.keys(), key=lambda x: x.split(\"_\")[-1]):\n    if len(learner.metric_values[metric_name]) > 0:\n        print(f\"{metric_name}: {learner.metric_values[metric_name][-1]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:28:36.502500Z","iopub.execute_input":"2023-01-09T17:28:36.503427Z","iopub.status.idle":"2023-01-09T17:28:36.523106Z","shell.execute_reply.started":"2023-01-09T17:28:36.503357Z","shell.execute_reply":"2023-01-09T17:28:36.521381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check most and least confused:","metadata":{}},{"cell_type":"code","source":"def predict(learner):\n    \n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        dl = learner.dataloaders[f\"{learner.stage}_dataloader\"]\n        loop = tqdm(dl, total=len(dl), leave=False)\n        for batch in loop:\n            inputs1 = batch[\"image1\"].to(learner.device)\n            inputs2 = batch[\"image2\"].to(learner.device)\n            labels = batch[\"label\"].to(learner.device)\n            all_labels.append(labels)\n\n            outputs = learner.model((inputs1, inputs2))\n            outputs = outputs.sigmoid()\n            all_outputs.append(outputs)\n    \n    all_labels = torch.hstack(all_labels)\n    all_outputs = torch.hstack(all_outputs)\n    \n    return all_outputs, all_labels\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:28:36.528944Z","iopub.execute_input":"2023-01-09T17:28:36.529842Z","iopub.status.idle":"2023-01-09T17:28:36.551188Z","shell.execute_reply.started":"2023-01-09T17:28:36.529782Z","shell.execute_reply":"2023-01-09T17:28:36.549662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_IMAGES_TO_SHOW = 5","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:28:36.560014Z","iopub.execute_input":"2023-01-09T17:28:36.563625Z","iopub.status.idle":"2023-01-09T17:28:36.571601Z","shell.execute_reply.started":"2023-01-09T17:28:36.563559Z","shell.execute_reply":"2023-01-09T17:28:36.570487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for stage in validation_stages:\n    print(\"-\"*30)\n    print(stage)\n    learner.stage = stage\n    \n    all_outputs, all_labels = predict(learner)\n    all_outputs = all_outputs.cpu()\n    all_labels = all_labels.cpu()\n    \n    is_correct = (all_outputs >= 0.5) == all_labels\n    not_correct_and_similar = (~is_correct) & (all_labels == 1)\n    print(f\"{is_correct.float().mean().item():.4f}\")\n    print(f\"{(~is_correct).long().sum().item()}/{len(is_correct)}\")\n    print(f\"{not_correct_and_similar.long().sum().item()}\")\n    \n    most_confused = (all_outputs - 0.5).abs()\n    most_confused = torch.vstack([most_confused, torch.arange(len(most_confused))])\n    \n    filtered_most_confused = most_confused[:, not_correct_and_similar]\n    \n    sorted_most_confused = filtered_most_confused[:, filtered_most_confused[0, :].argsort(descending=True)]\n    \n    initial_indices = sorted_most_confused[1, :].long()\n    \n    for idx in initial_indices[:N_IMAGES_TO_SHOW]:\n        x1, x2, same = learner.dataloaders[f\"{learner.stage}_dataloader\"].dataset._get_files_valid(idx)\n        \n        fig, axes = plt.subplots(1, 2)\n        for image, ax in zip([x1, x2], axes.flatten()):\n            ax.imshow(image)\n            ax.axis(\"off\")\n        \n        fig.suptitle(\"similar\" if same else \"dissimilar\")\n        fig.tight_layout()\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:28:36.572941Z","iopub.execute_input":"2023-01-09T17:28:36.573331Z","iopub.status.idle":"2023-01-09T17:30:12.112788Z","shell.execute_reply.started":"2023-01-09T17:28:36.573293Z","shell.execute_reply":"2023-01-09T17:30:12.110976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for stage in validation_stages:\n    print(\"-\"*30)\n    print(stage)\n    learner.stage = stage\n    \n    all_outputs, all_labels = predict(learner)\n    all_outputs = all_outputs.cpu()\n    all_labels = all_labels.cpu()\n    \n    is_correct = (all_outputs >= 0.5) == all_labels\n    print(f\"{is_correct.float().mean().item():.4f}\")\n    print(f\"{is_correct.long().sum().item()}/{len(is_correct)}\")\n    \n    least_confused = (all_outputs - 0.5).abs()\n    least_confused = torch.vstack([least_confused, torch.arange(len(least_confused))])\n    \n    filtered_least_confused = least_confused[:, is_correct]\n    \n    sorted_least_confused = filtered_least_confused[:, filtered_least_confused[0, :].argsort()]\n    \n    initial_indices = sorted_least_confused[1, :].long()\n    \n    for idx in initial_indices[:N_IMAGES_TO_SHOW]:\n        x1, x2, same = learner.dataloaders[f\"{learner.stage}_dataloader\"].dataset._get_files_valid(idx)\n        \n        fig, axes = plt.subplots(1, 2)\n        for image, ax in zip([x1, x2], axes.flatten()):\n            ax.imshow(image)\n            ax.axis(\"off\")\n        \n        fig.suptitle(\"similar\" if same else \"dissimilar\")\n        fig.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:30:12.115229Z","iopub.execute_input":"2023-01-09T17:30:12.116007Z","iopub.status.idle":"2023-01-09T17:31:47.848114Z","shell.execute_reply.started":"2023-01-09T17:30:12.115958Z","shell.execute_reply":"2023-01-09T17:31:47.846934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Assess influence of threshold:","metadata":{}},{"cell_type":"code","source":"%%time\n\nthresholds = np.linspace(start=0.1, stop=0.9, num=9)\nprint(thresholds)\n\nfor stage in [\"valid_balanced\"]:\n    print(stage)\n    learner.stage = stage\n    \n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    \n    for metric_function, label, ax in zip([accuracy_score, f1_score], [\"accuracy\", \"f1 score\"], axes.flatten()):\n        print(label)\n\n        values = []\n        for th in tqdm(thresholds, total=len(thresholds), leave=False):\n            with torch.no_grad():\n                y_true, y_predicted = iterate(learner=learner, perform_backward_pass=False, threshold=th, show_progress=False)\n            val = metric_function(y_true, y_predicted)\n            values.append(val)\n\n        ax.plot(thresholds, values, \"o-\")\n        ax.grid()\n        ax.set_title(label)\n\n    fig.suptitle(stage)\n    fig.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T12:57:57.121076Z","iopub.execute_input":"2023-01-10T12:57:57.121873Z","iopub.status.idle":"2023-01-10T13:10:59.219675Z","shell.execute_reply.started":"2023-01-10T12:57:57.121838Z","shell.execute_reply":"2023-01-10T13:10:59.218334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.metric_values[\"valid_balanced_acc\"][:9]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:22:04.651419Z","iopub.execute_input":"2023-01-10T13:22:04.651787Z","iopub.status.idle":"2023-01-10T13:22:04.661025Z","shell.execute_reply.started":"2023-01-10T13:22:04.651757Z","shell.execute_reply":"2023-01-10T13:22:04.659841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.metric_values[\"valid_balanced_f1\"][-9:]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:22:12.828076Z","iopub.execute_input":"2023-01-10T13:22:12.828558Z","iopub.status.idle":"2023-01-10T13:22:12.841269Z","shell.execute_reply.started":"2023-01-10T13:22:12.828515Z","shell.execute_reply":"2023-01-10T13:22:12.840148Z"},"trusted":true},"execution_count":null,"outputs":[]}]}